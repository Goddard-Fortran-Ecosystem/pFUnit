\documentclass[10pt]{article}
\usepackage{geometry}                % See geometry.pdf to learn the layout options. There are lots.
\geometry{letterpaper}                   % ... or a4paper or a5paper or ... 
%\geometry{landscape}                % Activate for for rotated page geometry
%\usepackage[parfill]{parskip}    % Activate to begin paragraphs with an empty line rather than an indent
\usepackage{graphicx}
\usepackage{amssymb}
\usepackage{epstopdf}
\DeclareGraphicsRule{.tif}{png}{.png}{`convert #1 `dirname #1`/`basename #1 .tif`.png}
\newcommand{\pfunit}{{\sc pFUnit }}
\title{pFUnit User's Guide}
\author{}
\date{October 2010}                                           % Activate to display a given date or no date


\begin{document}
\maketitle

\newpage

\tableofcontents

\newpage

\section{Overview}
\pfunit is a Fortran testing framework created by developers from NASA
SIVO's Advanced Software Technology Group.  That tool is intended to
encourage and simplify the process of using unit testing in routine
software development.  In particular, \pfunit is intended to enable
test-driven development (TDD) which requires developers to create
automated unit tests that define code requirements immediately before
writing the code itself.  The \pfunit (inspired by JUnit and CppUnit)
offers a convenient, lightweight mechanism for Fortran developers to
create and run software tests that specify the desired behavior for a
given piece of code. The initial ``p'' denotes the ability to test
parallelized Fortran code implemented via Message Passing Interface (MPI).

\newpage

\section{Installation}

\pfunit is intended to be very easy to build and install.  Because it
was developed using TDD, \pfunit comes bundled with a fairly thorough
suite of self-tests that should be built and executed prior to installation:

\subsection{System Requirements}

Before installing and building the \pfunit, make sure to follow the system requirements.

\subsubsection{Supported Operating Systems}
\begin{itemize}
  \item Linux
  \item Mac OS X
  \item IBM/AIX
\end{itemize}

\subsubsection{Supported Fortran Compilers}

\begin{enumerate}
	\item Open source compilers
	\begin{enumerate}
		 \item g95 (http://www.g95.org/)
		 \item gfortran (http://hpc.sourceforge.net/)
	\end{enumerate}
	
	\item Commerical compilers
	\begin{enumerate}
		 \item IntelÂ¨ Fortran Compiler Professional Edition release 11.1 \\
			(http://software.intel.com/en-us/intel-compilers/)
		 \item NAG Fortran Compiler Release 5.2 \\
			(http://www.nag.com/nagware/np.asp)
		 \item IBM XLF Compiler \\
			(http://www-01.ibm.com/software/awdtools/fortran/)
	\end{enumerate}

	\item MPI library from open source
	\begin{enumerate}
		 \item OpenMPI ( http://www.open-mpi.org/) 
	\end{enumerate}
\end{enumerate}

\subsection{Getting and Installing \pfunit}
\subsubsection{Obtaining \pfunit}

\pfunit is located at http://sourceforge.net/projects/pfunit/. To obtain the code use the "git clone" command as follows: 


\begin{verbatim}
$ git clone git://pfunit.git.sourceforge.net/gitroot/pfunit/pfunit pFUnit
\end{verbatim}


\subsubsection{Building \pfunit}

After the code of \pfunit is checked out, there are several build
options to support various configurations and compiler vendors. 
\begin{itemize}
\item The environment variable \verb+F90_VENDOR+ can be used to
  override the default Fortran compiler, which is Intel's ifort for
  most environments.
\item The environmnt variable \verb+MPI+ can be used to specify
  inclusion of support for MPI.  The default build supports only serial testing.
\end{itemize}


To build the serial implementation, one would issue the following command:
\begin{verbatim}
% make tests
\end{verbatim}
or, to use a different Fortran vendor:
\begin{verbatim}
% make tests F90_VENDOR=<vendor>
\end{verbatim}
Note that the list of vendors for the F90\underline{ }VENDOR:\\

\begin{tabular}{||c|c||}
  \hline
  F90\underline{ }VENDOR & Compiler name \\
  \hline
  GFortran & gfortran \\
  G95         & g95 \\
  Intel         & ifort \\
  NAG  & nagfor \\
  IBM & xlf \\
  \hline
\end{tabular}\\

For example, use the command line below:
\begin{verbatim}
% make tests F90_VENDOR=G95
\end{verbatim}

At this time, the number of serial self-tests in pFUnit is
coincidentally exactly equal to 100.  Thus, after a successful build one should see output that appears like:
\begin{verbatim}
....................................................................................................
100 run, 0 failed 0.04 seconds
\end{verbatim}

When building with MPI support the steps are much the same:	
\begin{verbatim}
% make tests MPI=YES
\end{verbatim}
or for using a specific Fortran compiler:
\begin{verbatim}
% make tests F90_VENDOR=<vendor> MPI=YES
\end{verbatim}
Note that such a build will require developers to always link the MPI
library to run even purely serial tests.  Developers of serial
applications are encouraged to use the serial implementation of
\pfunit.

\subsubsection{Installing \pfunit}
\begin{enumerate}
\item After building \pfunit is successful, install the build in a
  convenient directory and verify that the sub-directories bin,
  include, lib, mod are created.  Note: it it is very important to
  choose a different installation directory than was used for building pFUnit.
\begin{verbatim}
% make install INSTALL_DIR=<install-dir>
\end{verbatim}

\item To clean up after build:
\begin{verbatim}
% make distclean
\end{verbatim}

\item To uninstall, delete the installation directory and
  subdirectories.  Note that this is a \emph{dangerous} command, so
  please be careful.
\begin{verbatim}
% rm -r <install-dir>
\end{verbatim}
\end{enumerate}

\subsubsection{Setting PFUNIT environment variable}
After installing the \pfunit into the local directory, it would be
useful for adding the the \pfunit installation directory to the PFUNIT
environment variable.  The command following should be:
\begin{verbatim}
% export PFUNIT=<install-dir>
\end{verbatim}


%\subsection{}
\subsection{Supported environments}
\subsubsection{Operating System}

\pfunit itself makes very few assumptions about the underlying
operating system, but at this time has only been tested in a variety
of Unix environments  (Mac OS X, Linux, and IBM AIX).
The largest wrinkle users should encounter under Unix is the size of
pointers used by the OS ABI (i.e. 32-bit vs 64-bit).  At the time of
this writing, though, the number of 32-bit platforms is rapidly
dwindling.

Although a port to Windows variants should be straightforward, the
developers of \pfunit have no experience with those environments.  We
would welcome patches which enable such a port.

\subsubsection{Compiler Vendors}

Although \pfunit is intended to be as conforming to the Fortran
standard as possible, the initial implementation did require
interfacing to a small number of routines written in C, and such
interfaces are not strictly portable under the F95 standard.
Conditional preprocessing was used to provide portability and
typically require some extensions as new compilers are supported.

More recently, we have decided to use the C interoperability features
provided in the 2003 Fortran standard.  Although full implementations
of the 2003 standard are rare at this time (September 2009), most
Fortran vendors do now support the C interoperability subset of the
standard.  Users with compilers that do not support this
functionality are encouraged to ask their vendors why such support is
not available nearly 6 years after the standard has been established.
The need for C interoperability could of course be eliminated
completely (except for DSO support) by exploiting even more F2003
features, and, in fact, a fully object-oriented variant of \pfunit
implemented in pure F2003 is under development.  In the mean time, we
have compromised for maximum portability of the existing F95
implementation.\\

At this time the following Fortran implementations/versions are
supported:\\

\begin{tabular}{||c|c|l||}
\hline
Vendor & compiler name & version(s) \\
\hline
Intel & ifort & 11.1 \\
GNU   & gfortran & 4.4.1, 4.5.0 \\
g95   & g95   & 0.92 \\
IBM & xlf & 11.1, 12.1 \\
NAG & nagfor & 5.2 \\
\hline
\end{tabular}

\subsection{Porting to other compilers}
Because \pfunit is written in standard Fortran (for the most part -
see above) it should be easy to port to other Fortran compilers.  The
\pfunit developers would be happy to assist such a port, or even
perform the port ourselves if the user can provide access to the
corresponding environment/compiler.

If a compiler does not support the F2003 interoperability with C, we
will offer a port of an earlier release instead.  Relatively few user
interfaces have changed but there may be some documentation which is
incorrect for the earlier implementation.

\newpage

\section{Starting a new project}

When one starts a new project with \pfunit or brings \pfunit into an
existing project, it is absolutely essential to streamline the build
and subsequent execution of your suite of tests.  Several steps are
required to transform \pfunit tests from source code to an executable,
and invoking these steps should be as simple as \verb+% make tests+
for most projects.  Unfortunately there are numerous mutually
incompatible conventions among Fortran developers for managing the
builds of executables.  We provide a Makefile template that we believe
is quite clean and supports a certain style and set of conventions,
but many if not most developers will need to alter at least some
aspects to work with their own project.

Note: \pfunit build support assumes that tests are written in Fortran
``free-source format''.  Because \pfunit tests will generally be new
source code, we are unaware of any good reason to implement them in
the older fixed-source format.  (The user \emph{application} software,
can be written in either format of course.)

One complicating factor for assembling suites of tests in Fortran as
opposed to some languages such as python and Java is the lack of
``reflection''.  Language features in Java and python allow a
procedure to dynamically inquire about what methods are available in a
given class, and therefore to automatically create a list of
procedures that follow some naming convention for unit tests.  The
analogous feature in Fortran would be to use the language to create a
list of procedures that are made available by a given Fortran module.
In the absence of this convenience, we must use some external
source-code analysis script to automatically detect and assemble our
unit tests.  (Or, of course, simply assemble them manually.)  Note
that even with the extensions from the 2003 Fortran standard,
developers will need to assemble tests via some non-Fortran mechanism.

\pfunit comes with several scripts that can make the assembly and
compilation of unit tests largely automated.  Using these scripts adds
some complexity to the makefile but greatly simplifies the addition of
all subsequent tests.  Alternatively, a user can write their own test
executable which explicitly combines all unit-tests within a
test-suite (possibly with some hierarchical structure of sub-suites).
Incorporating such a scheme within a build system (e.g. make) is very
simple but requires the developer to explicitly add a reference to
each new test in the top-level driver.  Under this approach it is very
easy for the developer to forget to add new tests and not notice that
they are being skipped.



\subsection{Conventions for Managing test suites}

\subsubsection{Building test suites manually}
Once the module including the functions and/or subroutines is complete
for the development, that module will need to get testing for
verification.  The next step is to use the test driver.  However, the
test driver will need the test module containing the developed module.

%\subsection{Manual - how to write a test driver}
\begin{enumerate}
\item Adding a test to a suite\\
An example of a test that tests a cross product implementation is:

\begin{verbatim}
! cross product of vector with itself is 0
subroutine testSameVector()
   use pFUnit
   use VectorOperations
   implicit none
   real :: a(3), c(3)

   a = (/ 1, 2, 3 /)
   c = vectorCrossProduct(a, a)
   
   call assertEqual(0, c) ! vector comparison with 0 tolerance
   
end subroutine testSameVector
\end{verbatim}

Such a test can be implemented in a file that contains various tests
to test the cross product, say testVectorProduct.F90, or in a
module,  say testVectorProduct\_mod.F90.

\item An example driver program\\
You will need the following template of test driver required for
performing the test.  Note that \emph{TODO} shows that it will need to
update the code to follow up with the test module.

\begin{verbatim}
program TestDriver
   use pFUnit
   !! @TODO: need to include ("use") the test module
   !! e.g. "use TestVectorProduct_mod"
   !! or    "external testSameVector"

   implicit none

   type (TestSuite_type) :: suite
   type (TestResult_type) :: result
   character(len=100) :: summary_statement

   call pFUnit_init()

   !! @TODO:  Need to initialize main test suite
   !! e.g.  suite = TestSuite('name of suite')

   !! @TODO: Need to list/accumulate test procedures
   !! e.g. call add(suite, TestCase1Step('testSameVector',testSameVector))

   !! Run the tests and accumulate the results in "result"
   result = newTestResult(mode=MODE_USE_STDOUT)
   call Run(suite,result)

   summary_statement = Summary(result)
   print *, trim(summary_statement)

   call clean(result)
   call clean(suite)
   call pFUnit_finalize()
  
end program TestDriver
\end{verbatim}

\item Declaration \\
The test driver needs at least three objects to be declared.   The following first three objects are:

\begin{enumerate}
\item \textbf{\emph{TestSuite}\underline{ }type} treats the collections of test case
\item \textbf{\emph{TestResult}\underline{ }type} gathers data about successes and failures for a series of runs.
\item \textbf{\emph{summary\underline{ }statement}} identifies message for the result from runs.  
\end{enumerate}

\item Initialing and Finalizing \pfunit \\
After declaring data types including these objects above, the method \textbf{\texttt{pFUnit\underline{ }init}} is required to use for the pFUnit initialization.  And, using the method \textbf{\texttt{clean}} for clearing up the objects of result and test suite at the end of code.    The following steps for initialing and finalizing are:
\begin{verbatim}
   call pFUnit_init()
   ...
   ...
   ...
   call clean(result)
   call clean(suite)
   call pFUnit_finalize()
\end{verbatim}

\item Build suite \\
After adding the method  \textbf{\texttt{pFUnit\underline{ }init}}, suite is needed to build from test procedures.

\begin{verbatim}
   suite = TestSuite('vector tests')
\end{verbatim}

The variable \textbf{\texttt{'suite'}} is constructed with the test name 'vector tests' for its example.

\end{enumerate}


\subsubsection{Automated test to a suite}

\begin{enumerate}
\item Supported style\\
The more automated approach offered by \pfunit consists of the
following conventions/steps.  First, all tests are assumed to be in
the form of module procedures (i.e. contained within an f90 module) in
a separate test directory.  Further each test procedure is expected to
begin with the string ``test'' e.g.

\begin{verbatim}
module testVectorProduct_mod
  implicit none
  private

  public :: testSameVector
  public :: testOrthogonalVectors
  !! etc...

! cross product of vector with itself is 0
subroutine testSameVector()
   use pFUnit
   use VectorOperations
   implicit none
   real :: a(3), c(3)

   a = (/ 1, 2, 3 /)
   c = vectorCrossProduct(a, a)
   
   call assertEqual(0, c) ! vector comparison with 0 tolerance
   
end subroutine testSameVector

!! etc..

end module testVectorProduct_mod

\end{verbatim}

\item Automatic creation of a wrapper module\\
The script ``wrapTest" in the \pfunit bin directory will use the C
preprocessor to create a wrapper module for each such module.  This
wrapper module essentially adds a function suite() which returns a
\pfunit testSuite object consisting of one test for each test
procedure in the original file.  The ``wrapTest" script also appends
the name of the module to a file called ``suite\underline{ }list" which is used
by the included driver program to create a master testSuite that
incorporates all module test suites.

Note: Part of the assembly process associates a string (name of
procedure) with a procedure reference (the unit test), and this
operation is unfortunately handled in different ways by various C
preprocessors (and from version-to-version).  \pfunit currently
supports at least 4 styles of stringification, but the user may need
to pass a flag to ensure that the scripts attempt the correct style.

The main driver is in ./include/skeleton.F90 and must be again
preprocessed by a C preprocessor with similar caveats as above.

And of course, there are dependency issues associated with all of this:

\begin{verbatim}
# make fragment
TEST_SRCS = $(notdir $(wildcard $(TEST_DIR)/test*.F90))
WRAP_SRCS = $(TEST_SRCS:%.F90=%_wrap.F90)
TEST_OBJS=$(TEST_SRCS:%.F90=%.o)
WRAP_OBJS=$(TEST_OBJS:%.o=%_wrap.o)
\end{verbatim}

Dependencies:
\begin{verbatim}
%_wrap.o: %
\end{verbatim}

Rules:
\begin{verbatim}
%_wrap.F90: %.F90
        $\pfunit/bin/wrapTest $< $@
\end{verbatim}

\item Makefile sample for supporting automation

The following Makefile snippet could be used, with minor
modifications, to support the automation just described. 

\begin{verbatim}
COMPONENTS := VectorOperations Integrators 

PFUNIT_TEST_DIRECTORIES = $(foreach ITEM,$(COMPONENTS), ./$(ITEM))

SOURCE_DIR := $HOME/math

PFUNIT_LFLAGS += $(foreach ITEM,$(COMPONENTS), -L$(SOURCE_DIR)/$(ITEM) -l$(ITEM))

EXTRA_FFLAGS += $(foreach ITEM,$(COMPONENTS), -I$(SOURCE_DIR)/$(ITEM))

MPI_FC=mpif90
CSTRING = $(shell mpif90 --version)
COMPILER = $(findstring ifort, $(CSTRING))

ifeq ($(COMPILER),ifort)
  FC =ifort
  EXTRA_FFLAGS += -g -O0 -traceback -fpp -O2 
else
  FC =gfortran
  EXTRA_FFLAGS += -g -O0 
endif

EXTRA_FFLAGS += $(CPPFLAGS)

MPIRUN=mpirun
PFUNIT_USE_MPI=YES
PFUNIT_NPES=5

clean: 
        make pfunitdistclean
        $(RM) *.o *_wrap.F90 *.mod suite_list

distclean:
        make clean

ifdef PFUNIT
  include $(PFUNIT)/include/pFUnit.makefile
endif

EXECS = $(foreach ITEM,$(COMPONENTS), $(SOURCE_DIR)/$(ITEM)/lib$(ITEM).a)

$(PFUNIT_TEST_EXECUTABLE) : $(EXECS)

%.o : %.F90
        $(FC) -c $(EXTRA_FFLAGS) $($(PFUNIT_FFLAGS_VARIABLE)) $<

\end{verbatim}

\end{enumerate}



\section{Writing tests}

By far the best way to learn how to use \pfunit is to look at some
existing examples.

Suppose one wanted to test a function that should calculate
\[
f = \sum_{i=1}^{n} \frac{1}{A_i}
\]

One simple test would be to confirm the behavior for an array of size
1 with a simple entry.
\begin{verbatim}
subroutine testSumInverseEmpty()
  real :: array(1)
  real :: fResult
  array(1) = 1./2
  fResult = f(array)
  call assertEqual(2., fResult, tolerance=0.000001)
end subroutine testSumInverseEmpy
\end{verbatim}

This test consisted of 3 (rather simple) parts:
\begin{enumerate}
\item establishing a certain state of the system (input arguments)
\item invoking the test, f(array), also referred as system under test (SUT)
\item checking the post conditions (expected values)
\end{enumerate}

A slightly more complex case would be to use a small number of
elements with simple entries.  Note that we now inline the call to the
SUT within the assert since for simple interfaces this is actually
clearer:

\begin{verbatim}
subroutine testSumInverseEmpty()
  real :: array(3)
  array(1) = 1./2
  array(2) = 1./3
  array(3) = 1./5
  call assertEqual(2.+3.+5., f(array), tolerance=0.000001)
end subroutine testSumInverseEmpy
\end{verbatim}


That really is pretty much it for writing tests.  Of course we now
need to explain the API for assertEqual() and a small number of other
framework interfaces.


\subsection{Assertions and other variants}

The primary \pfunit interfaces which appears in user tests are those
associated with assertions.  Each assertion is represents a condition
that should be true at that point, and if not the framework will raise
an exception and declare that this particular test has failed.  The
vast majority of assertions are of the form:
\begin{verbatim}
CALL assertEqual(<expected>, <found>)
\end{verbatim}
The assertEqual() interface is heavily overloaded for multiple data
types (integer, real, double, complex), kinds, and ranks (scalar, 1D,
...).


A simple example of using an assert could be:
\begin{verbatim}
CALL assertEqual(3, 1+2)
\end{verbatim}

When an assertion fails, the framework will report which test failed,
the expected and found values at the point of the assertion.  In the
case of arrays, the framework will list the first discrepancy (in
dictionary order) as well as the location within the array.

For floating point assertions, there is an optional argument
``tolerance'' which is 0 by default.  Although exact comparison of
floating point quantities is generally a bad idea in actual code, it
can be very desirable in certain very precise test situations.
Tolerance is expressed as \emph{absolute} tolerance as opposed to
\emph{relative} tolerance.



If a user wants to compare two quantities that are not directly
supported by assertEqual(), she can extend that interface for her own
data types, or more simply (but less precisely) use the generic assertTrue():

\begin{verbatim}
CALL assertTrue(<condition>)
\end{verbatim}

For example to check that all values of an array are less than 0.5, one could write:
\begin{verbatim}
CALL assertTrue(ALL(array(:) < 0.5))
\end{verbatim}

Often it is useful to add a more descriptive message to an assertion,
especially for assertTrue().  All assertions have an optional
``message'' argument which is reported along with the other circumstances of failure.

\emph{TO DO: options to report file and line number would be very
  desirable but have not been implemented at this time.  The interface
  gets a bit crowded with such an extension.  E.g.  comparing 2
  floating point arrays could potentially involve no fewer than 6
  arguments: expected, found, tolerance, message, file, line.  }

\subsection{Other useful features}
Although assertions are sufficient for the vast majority of unit
tests, there are a few other useful interfaces available for some specialized situations.

\subsubsection{File manipulation}
Many tests need to provide the SUT (i.e. user routines) with an input
file or alternatively examine a file produced by the SUT.  (Fortran
unfortunately has no true ability to use strings as a substitute for a
file.  Internal files are almost there, but because they do not use a
unit number they cannot be substituted.)

The IO\underline{ }Utilities.F90 module in \pfunit is very useful for getting an
unused unit number, opening/closing and deleting files.  Users that
are using ad-hoc unit numbers in their source code may wish to adopt
this module for purposes beyond unit testing.

\subsubsection{Exceptions}
Although this is less common with Fortran applications, it may be
desirable to have a unit test to detect that the SUT fails
``correctly'' under given circumstances.  E.g. that the SUT reports an
illegal value for an array entry.  In older conventions, procedures
used integer return codes, but an alternative that may be more
comfortable for developers coming from C++ or JAVA would be to have
the SUT ``throw'' an exception.  (Aging Fortran does not actually
have exceptions so this is a crude approximation.)  The unit test can
then ``assert'' that the exception was thrown.

\begin{verbatim}
...
if (denominator == 0.) then
   call throw('denominator cannot be 0')
   return
end if
...
\end{verbatim}

\begin{verbatim}
...
call sut(...)
call assertTrue(catch('denominator cannot be 0'))
...
\end{verbatim}

\begin{verbatim}
...
call sut(...)
call assertTrue(catchAny())
...
\end{verbatim}

\subsection{Test Fixtures}
When a group of tests require identical (or \emph{very} similar)
states prior to calling the SUT, clarity can be improved by moving the
corresponding logic into a setUp() routine which initialized a test
``fixture'' which is simply a derived type for containing any data
that the test will need to access.  (A corresponding tearDown()
routine is used to combine any common cleanup (e.g. array
deallocation) at the end of the tests.

When using fixtures, a fresh fixture is created and initialized by
setUp() prior to \emph{each} test.  Thus though the tests share
\emph{logic}, they do not share \emph{data} amongst themselves.
Preserving test independence is a very important aspect of testing.

\subsection{Tests involving MPI}

Tests of procedures which involve MPI have some important differences
with conventional tests.  In particular, they require an additional
parameter which specifies how many processes should be used during the
test.  Also, since almost any meaningful test will need to determine
the process ``rank'' and the size of the MPI communicator use for the
test (\emph{NOT} \verb+MPI_COM_WORLD+!) \pfunit passes in a TestInfo
object which enables easy access to such information.

Because most interesting tests of parallel code should be executed on
a variety of process counts, \pfunit allows the developer to specify an array
containing the number of processes to use when constructing an MPI test.

\hspace{0.1in}
\emph{ Note: Although broken serial code can also ``hang'', most developers
  will encounter such a situation very rarely.  Unfortunately, it is
  far easier to have deadlock (or live-lock or even an abort) with MPI
  code under development.  There is no good way for \pfunit to handle
  recover from such issues.  Interested developers can look into the use of the DSO
  interface which presents a possibly more robust (but less portable)
  approach to this issue.}

\hspace{0.1in}
\emph{ A purist may complain that MPI should be ``relaunched'' for
  each test. Unfortunately most MPI implementations are not
  re-entrant. Earlier versions of \pfunit handled MPI tests by
  launching a fresh executable for each MPI test using temporary files to
  coordinate information transfer.  Unfortunately the O(1 sec) startup
  time for MPI with even a small number of processes was too slow for
  running large sets of tests.}

If any process throws an exception (e.g. fails an assertion), \pfunit
declares that the test has failed.


%\section{Accumulating tests into suites}


\section{Running tests}
\subsection{Running tests under MPI}

To build and run tests under MPI one must use a configuration of
\pfunit compiled with MPI=YES and one must launch the \pfunit driver
with ``mpirun''.

When building tests manually, registration of MPI tests require an
extra parameter specifying the number of processes to use:

\begin{verbatim}
call add(suite, & &   MpiTestCase('testMPI', testMPI, numProcesses=3))
\end{verbatim}

Note that \pfunit creates a new subcommunicator for each MPI test when it is run
and serial tests are only run on the root process. 

When using the automated build the only requirement to run build/run
under MPI is that the following string:

\begin{verbatim}
! *** MPI Test Cases ***
\end{verbatim}

be the first line in the test module.

\section{FAQ}


\section{Examples}
The purpose of showing examples is to help users and developers understanding the codes of the test driver manually and automation.   The file README in those top level of its subdirectories (Manual\underline{ }TestCase\underline{ }Wrappers and Template\underline{ }TestCase\underline{ }Wrappers) instructs how to build the sample application using the makefile.    Both of those directories have the following subdirectories for the comparison between manual and automated building applications.    
\begin{enumerate}
\item Simple\underline{ }Example
\item Fixture\underline{ }Example
\item SumInverse\underline{ }Example
\item Halo\underline{ }Fill\underline{ }Example
\end{enumerate}

Also, there is the file 'README' in each of those directories for the instruction of how to use makefile for building application.


\subsection{Manual}
The manual examples is located in the ./pFUnit/Examples/Manual\underline{ }TestCase\underline{ }Wrappers directory.

\subsubsection{Simple\underline{ }Example}
Let's start with the \emph{Simple\underline{ }Example} directory:

{\small \begin{verbatim}
Simple_Example> ls
CVS			GNUmakefile		VectorOperations.F90	driver.F90		tests.F90

Simple_Example> make
ifort -c -I/Users/johndoe/dev/pFUnit_Intel/mod VectorOperations.F90
ifort -c -I/Users/johndoe/pFUnit_Intel/mod tests.F90
ifort -c -I/Users/johndoe/pFUnit_Intel/mod driver.F90
ifort -o simple.x VectorOperations.o driver.o tests.o -L/Users/johndoe/pFUnit_Intel/lib -lpfunit
./simple.x
...  
Failure in vector tests::testFailOnPurpose - Integer scalar assertion failed: Intentional 
failure for instructional purposes.
       Expected:  1
       but found: 2
x. 4 run, 1 failed (1 severe) 0.00 seconds

Simple_Example> ls
CVS			VectorOperations.F90	driver.F90		simple.x		tests.o
GNUmakefile	VectorOperations.o		driver.o		tests.F90		vectoroperations.mod

Simple_Example> make distclean
rm -f VectorOperations.o driver.o tests.o
rm -f *.mod
rm -f simple.x

Simple_Example> ls
CVS			GNUmakefile		VectorOperations.F90	driver.F90		tests.F90
\end{verbatim}
}


\subsubsection{Fixture\underline{ }Example}

{\small \begin{verbatim}
Manual_TestCase_Wrappers> cd Fixture_Example/
Fixture_Example> ls
CVS			GNUmakefile		driver.F90		testUseFixture_mod.F90

Fixture_Example> make
ifort -c -I/Users/johndoe/pFUnit_Intel/mod testUseFixture_mod.F90
ifort -c -I/Users/johndoe/pFUnit_Intel/mod driver.F90
ifort -o fixture.x driver.o testUseFixture_mod.o -L/Users/johndoe/pFUnit_Intel/lib -lpfunit
./fixture.x
..  
 2 run, 0 failed 0.00 seconds
 
\end{verbatim}
}

\subsubsection{SumInverse\underline{ }Example}

{\small \begin{verbatim}
Manual_TestCase_Wrappers> cd SumInverse_Example/
SumInverse_Example> make
make -C src  all
ifort -c -I. -I../mod SumInverse_mod.F90 
ar -cr libsuminverse.a SumInverse_mod.o
mkdir -p ../lib
mkdir -p ../mod
cp libsuminverse.a ../lib/.
cp suminverse_mod.mod ../mod/.
make -C tests  all
ifort -c -I. -I../mod -I/Users/johndoe/pFUnit_Intel/mod TestSumInverse_mod.F90 
ifort -c -I. -I../mod -I/Users/johndoe/pFUnit_Intel/mod TestDriver.F90 
ifort TestDriver.o TestSumInverse_mod.o -o test.x -L../lib -lsuminverse -L/Users/johndoe/pFUnit_Intel/lib 
-lpfunit
... 3 run, 0 failed 0.00 seconds

\end{verbatim}
}


\subsubsection{Halo\underline{ }Fill\underline{ }Example using MPI library}

{\small \begin{verbatim}
Manual_TestCase_Wrappers> cd Halo_Fill_Example/
Halo_Fill_Example> export PFUNIT=~/pFUnit_Intel_MPI

Halo_Fill_Example> export PATH=/opt/openmpi-1.4.1_ifort/bin:$PATH

Halo_Fill_Example> ls
CVS			Halo_mod.F90		testHalo_mod.F90
GNUmakefile		driver.F90

mpif90 -c -I/Users/johndoe/pFUnit_Intel_MPI/mod Halo_mod.F90
mpif90 -c -I/Users/johndoe/pFUnit_Intel_MPI/mod testHalo_mod.F90
mpif90 -c -I/Users/johndoe/pFUnit_Intel_MPI/mod driver.F90
mpif90 -o halo.x Halo_mod.o driver.o testHalo_mod.o -L/Users/johndoe/pFUnit_Intel_MPI/lib -lpfunit
mpirun -np 5 ./halo.x
mmm  
 3 run, 0 failed 0.00 seconds

\end{verbatim}
}

\subsection{Automation}

\subsubsection{Simple\underline{ }Example}

{\small \begin{verbatim}
Examples> cd Template_TestCase_Wrappers/
Template_TestCase_Wrappers> ls
CVS			Halo_Fill_Example	Simple_Example
Fixture_Example		README			SumInverse_Example

Template_TestCase_Wrappers> cd Simple_Example/

Simple_Example> ls
CVS			NOTES			tests_mod.F90
GNUmakefile		VectorOperations.F90

Simple_Example> make
ifort -c -I/Users/johndoe/pFUnit_Intel/include -I/Users/johndoe/pFUnit_Intel/mod -I. VectorOperations.F90
ifort -c -I/Users/johndoe/pFUnit_Intel/include -I/Users/johndoe/pFUnit_Intel/mod -I. tests_mod.F90
CONVERTING FILE: tests_mod.F90 tests_mod_wrap.F90
ifort -c -I/Users/johndoe/pFUnit_Intel/include -I/Users/johndoe/pFUnit_Intel/mod -I. tests_mod_wrap.F90
ifort -o tests.x -I/Users/johndoe/pFUnit_Intel/include -I/Users/johndoe/pFUnit_Intel/mod -I. /Users/johndoe/pFUnit_Intel/include/driver.F90  tests_mod_wrap.o  tests_mod.o -L/Users/johndoe/pFUnit_Intel/lib -lpfunit VectorOperations.o
./tests.x     
  
Failure in top::tests_mod::testFailOnPurpose - Integer scalar assertion failed: Intentional failure for 
instructional purposes.
       Expected:  1
       but found: 2
....
 4 run, 1 failed (1 severe) 0.00 seconds
\end{verbatim}
}

\subsubsection{Fixture\underline{ }Example}

{\small \begin{verbatim}
Simple_Example> cd ../Fixture_Example/
Fixture_Example> ls
CVS			GNUmakefile		testUseFixture_mod.F90

Fixture_Example> make
ifort -c -I/Users/johndoe/pFUnit_Intel/include -I/Users/johndoe/pFUnit_Intel/mod -I.  testUseFixture_mod.F90
CONVERTING FILE: testUseFixture_mod.F90 testUseFixture_mod_wrap.F90
ifort -c -I/Users/johndoe/pFUnit_Intel/include -I/Users/johndoe/pFUnit_Intel/mod -I.  testUseFixture_mod_wrap.F90
ifort -o tests.x -I/Users/johndoe/pFUnit_Intel/include -I/Users/johndoe/pFUnit_Intel/mod -I. /Users/johndoe/pFUnit_Intel/include/driver.F90  testUseFixture_mod_wrap.o  testUseFixture_mod.o -L/Users/johndoe/pFUnit_Intel/lib -lpfunit 
./tests.x     
..
 2 run, 0 failed 0.00 seconds
\end{verbatim}
}

\subsubsection{SumInverse\underline{ }Example}

{\small \begin{verbatim}
Fixture_Example> cd ../SumInverse_Example/
SumInverse_Example> ls -R
CVS		GNUmakefile	src		tests

../src:
CVS			GNUmakefile		SumInverse_mod.F90

./tests:
CVS			GNUmakefile		TestSumInverse_mod.F90

SumInverse_Example> make
make -C src  all
ifort -c -I. -I../mod SumInverse_mod.F90 
ar -cr libsuminverse.a SumInverse_mod.o
mkdir -p ../lib
mkdir -p ../mod
cp libsuminverse.a ../lib/.
cp suminverse_mod.mod ../mod/.
make -C tests  all
ifort -c -I. -I../mod -I/Users/johndoe/pFUnit_Intel/include -I/Users/johndoe/pFUnit_Intel/mod -I. 
TestSumInverse_mod.F90
CONVERTING FILE: TestSumInverse_mod.F90 TestSumInverse_mod_wrap.F90
ifort -c -I. -I../mod -I/Users/johndoe/pFUnit_Intel/include -I/Users/johndoe/pFUnit_Intel/mod -I.
 TestSumInverse_mod_wrap.F90
ifort -o tests.x -I. -I../mod -I/Users/johndoe/pFUnit_Intel/include -I/Users/johndoe/pFUnit_Intel/mod -I. 
/Users/johndoe/pFUnit_Intel/include/driver.F90 -L../lib -lsuminverse  TestSumInverse_mod_wrap.o  
TestSumInverse_mod.o -L/Users/johndoe/pFUnit_Intel/lib -lpfunit 
./tests.x     
...
 3 run, 0 failed 0.00 seconds

\end{verbatim}
}

\subsubsection{Halo\underline{ }Fill\underline{ }Example using MPI library}

{\small \begin{verbatim}
Template_TestCase_Wrappers> cd Halo_Fill_Example/
Halo_Fill_Example> make
mpif90 -c -I/Users/johndoe/pFUnit_Intel_MPI/include -I/Users/johndoe/pFUnit_Intel_MPI/mod -I.  Halo_mod.F90
mpif90 -c -I/Users/johndoe/pFUnit_Intel_MPI/include -I/Users/johndoe/pFUnit_Intel_MPI/mod -I.
  testHalo_mod.F90
CONVERTING FILE: testHalo_mod.F90 testHalo_mod_wrap.F90
mpif90 -c -I/Users/johndoe/pFUnit_Intel_MPI/include -I/Users/johndoe/pFUnit_Intel_MPI/mod -I. 
 testHalo_mod_wrap.F90
mpif90 -o tests.x -I/Users/johndoe/pFUnit_Intel_MPI/include -I/Users/johndoe/pFUnit_Intel_MPI/mod
 -I. /Users/johndoe/pFUnit_Intel_MPI/include/driver.F90  testHalo_mod_wrap.o  testHalo_mod.o 
 -L/Users/johndoe/pFUnit_Intel_MPI/lib -lpfunit Halo_mod.o
mpirun    -np 6 ./tests.x     
 
 3 run, 0 failed 0.00 seconds
\end{verbatim}
}

\section{Troubleshooting}


\end{document}  
